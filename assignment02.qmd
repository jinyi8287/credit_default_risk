---
title: "assignment02"
format: pdf
editor: visual
---





## Executive Summary

Executive Summary 可能會這樣寫：
This report investigates the drivers of credit card churn at Tifosi Bank using predictive modelling. We identified transaction frequency and account activity as the strongest predictors of churn. By applying SMOTE and XGBoost, we improved the model’s recall to 82%. Based on our findings, we recommend that Tifosi Bank implement proactive outreach strategies for low-activity, high-limit customers to reduce attrition risk.

Introduction 會這樣寫：
Credit card attrition represents a critical threat to Tifosi Bank’s long-term profitability. With up to 25% of revenue tied to credit card operations, losing high-value customers not only reduces immediate income but undermines future cross-sell opportunities. This report investigates what drives customer churn and how analytics can inform more effective retention strategies.


## Introduction

Credit card churn has a direct impact on the profitability and strategic growth of retail banks.Credit card operations can account for up to 25% of a bank’s retail revenue, driven by interest earnings, interchange fees, annual fees, and cross-selling potential of other product and service.According to McKinsey's global payments insights, credit card operations can contribute significantly up to 25% to a bank's retail revenue.

For Tifosi Bank,the rise of attrition in credit card segment signals more than a loss of revenue but also reflects a shift of customer's satisfaction or loyalty.Hence, it is crucial to identify at-risk customers and understand the key drivers of churn.

In this report, we will explore the key factors contributing to credit card churn at  Tifosi Bank by applying predictive modeling techniques.These insights are then translated into actionable strategies to support customer retention.





## Analytical Overview 




```{r,message=FALSE,warning=FALSE}
#package
library(tidyverse)
library(tidymodels)
library(janitor)
library(skimr)
library(here)
library(readr)
tidymodels_prefer()
```



```{r,message=FALSE}
#load in data
raw_data<-read_csv(here("Data","bank_churners.csv")) %>% 
  clean_names()

```


```{r}
skim(raw_data)
```


#### Data overview

The dataset from Tifosi Bank consists of 10127 credit card customers ,characterised by  three main feature groups : demographic information (e.g., age, income, education), behavioural indicators (e.g., transaction counts, credit usage), and account relationship metrics (e.g., months on book, product count).The target variable for this report is attrition_flag which is a binary indicator that represents whether the customer remained or left

#### Attrition_Flag HOW many?

```{r,message=FALSE,echo=FALSE}
ggplot(raw_data, aes(x = attrition_flag, fill = attrition_flag)) +
  geom_bar() +
  geom_text(stat = "count", aes(label = scales::percent(after_stat(count) / sum(after_stat(count)))), 
            vjust = -0.2, size = 4) +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed")) +
  labs(
    title = "Churn is Rare, But Crucial: Only 16% Leave",
    subtitle = "Based on 10,127 credit card customers",
    x = "Customer Status",
    y = "Number of Customers"
  ) +
  theme_minimal() +
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5), plot.subtitle = element_text(hjust = 0.5))

```


```{r}
library(ggplot2)
library(dplyr)

# 計算各類別比例
pie_data <- raw_data %>%
  count(attrition_flag) %>%
  mutate(percentage = n / sum(n),
         label = paste0(attrition_flag, ": ", scales::percent(percentage, accuracy = 0.1)))

# 畫出 pie chart
ggplot(pie_data, aes(x = "", y = percentage, fill = attrition_flag)) +
  geom_col(width = 1, color = "white") +
  coord_polar(theta = "y") +
  geom_text(aes(label = label), position = position_stack(vjust = 0.5), size = 4.5) +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed")) +
  labs(
    title = "Customer Attrition Distribution",
    fill = "Customer Status"
  ) +
  theme_void() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 11)
  )

```


這裡我們得出一個資訊，其實通常客戶流失、信用欺詐等數據分析專案都是所謂的「不平衡資料集」，也就是說流失屬於「稀少事件」，那麼在大型數據（幾億筆資料）我們會用抽樣方法來平衡兩者 不過今天這筆資料集只有7000多，我們可以改用加權的方式處理。






```{r,message=FALSE,echo=FALSE}
library(forcats)
library(dplyr)
library(janitor)
library(tidyr)
library(ggplot2)

# 交叉表 + 百分比
income_tab <- raw_data %>%
  tabyl(income_category, attrition_flag) %>%
  adorn_percentages("row") %>%
  adorn_totals("row") %>%
  adorn_pct_formatting(digits = 1)

income_long <- income_tab %>%
  filter(income_category != "Total") %>%
  pivot_longer(cols = -income_category, names_to = "attrition_flag", values_to = "percent")

# 計算實際筆數
income_counts <- raw_data %>%
  count(income_category, attrition_flag)

# 合併百分比與筆數，這才是你真正要畫圖的資料框
income_plot_data <- left_join(income_counts, income_long, by = c("income_category", "attrition_flag")) %>%
  mutate(income_category = fct_relevel(income_category,
    "< $40K", "$40K - $60K", "$60K - $80K", "$80K - $120K", "> $120K", "Unknown"
  ))

# 繪圖
ggplot(income_plot_data, aes(x = income_category, y = n, fill = attrition_flag)) +
  geom_col(position = "dodge") +
  geom_text(aes(label = percent),
            position = position_dodge(width = 0.9), vjust = -0.3, size = 4) +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed")) +
  labs(
    title = "Lower-income Customers Show Higher Churn Rates",
    subtitle = "Based on 10,127 credit card customers",
    x = "Income Level",
    y = "Number of Customers"
  ) +
  theme_minimal() +
  theme(legend.title = element_blank(),
        plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))


```





#### card category

```{r,message=FALSE,echo=FALSE}
unique(raw_data$card_category)

# 交叉表 + 百分比
card_tab <- raw_data %>%
  tabyl(card_category, attrition_flag) %>%
  adorn_percentages("row") %>%
  adorn_totals("row") %>%
  adorn_pct_formatting(digits = 1)

card_long <- card_tab %>%
  filter(card_category != "Total") %>%
  pivot_longer(cols = -card_category, names_to = "attrition_flag", values_to = "percent")


# 計算實際筆數
card_counts <- raw_data %>%
  count(card_category, attrition_flag)

#合併為繪圖資料框
card_plot_data <- left_join(card_counts, card_long, by = c("card_category", "attrition_flag"))

#排序
library(forcats)
card_plot_data <- card_plot_data %>%
  mutate(card_category = fct_relevel(card_category, "Blue", "Silver", "Gold", "Platinum"))


# 繪圖
ggplot(card_plot_data, aes(x = card_category, y = n, fill = attrition_flag)) +
  geom_col(position = "dodge") +
  geom_text(aes(label = percent),
            position = position_dodge(width = 0.9), vjust = -0.3, size = 4) +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed")) +
  labs(
    title = "Customer Churn by Credit Card Category",
    subtitle = "Based on 10,127 credit card customers",
    x = "Card Category",
    y = "Number of Customers"
  ) +
  theme_minimal() +
  theme(legend.title = element_blank(),
        plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))

```

#### income category

```{r}


# 查看類別順序
unique(raw_data$income_category)

# 建立交叉表 + 百分比
income_tab <- raw_data %>%
  tabyl(income_category, attrition_flag) %>%
  adorn_percentages("row") %>%
  adorn_totals("row") %>%
  adorn_pct_formatting(digits = 1)

# 長格式資料
income_long <- income_tab %>%
  filter(income_category != "Total") %>%
  pivot_longer(cols = -income_category, names_to = "attrition_flag", values_to = "percent")

# 計算實際筆數
income_counts <- raw_data %>%
  count(income_category, attrition_flag)

# 合併資料
income_plot_data <- left_join(income_counts, income_long, by = c("income_category", "attrition_flag"))

# 設定順序
income_plot_data <- income_plot_data %>%
  mutate(income_category = fct_relevel(income_category,
    "< $40K", "$40K - $60K", "$60K - $80K", "$80K - $120K", "> $120K", "Unknown"
  ))

# 繪圖
ggplot(income_plot_data, aes(x = income_category, y = n, fill = attrition_flag)) +
  geom_col(position = "dodge") +
  geom_text(aes(label = percent),
            position = position_dodge(width = 0.9), vjust = -0.3, size = 4) +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed")) +
  labs(
    title = "Customer Churn by Income Level",
    subtitle = "Based on 10,127 credit card customers",
    x = "Income Category",
    y = "Number of Customers"
  ) +
  theme_minimal() +
  theme(legend.title = element_blank(),
        plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))

```

💳 Credit Card Category（卡片類別）
目標：檢查不同卡別（Blue, Silver, Gold, Platinum）是否與流失率有關。

觀察：

大多數客戶集中在 Blue 卡，且這一類卡的流失率略高。

Platinum 雖然人數少，但流失率最高（25%）。

解釋：可能代表低價值客戶（Blue）更容易流失，或高價值客戶若流失，會帶來更高影響。

💰 Income Level（收入層級）
目標：查看不同收入層級的顧客是否有不同的流失傾向。

觀察：

年收入越低的族群，其流失率越高（例如：< $40K 有 17.2% 流失）。

收入越高的族群（如 >$120K），流失率相對低。

解釋：可能代表經濟能力較弱者在信用卡使用與忠誠度上更不穩定。

# demographic 



#### gender

```{r,message=FALSE,echo=FALSE}
library(janitor)
library(dplyr)
library(tidyr)
library(ggplot2)

# 建立交叉表 + 百分比
gender_tab <- raw_data %>%
  tabyl(gender, attrition_flag) %>%                     # 建立交叉表
  adorn_percentages("row") %>%                          # 每列內算百分比（男自己算，女自己算）
  adorn_totals("row") %>%                               # 加上 Total 行（後面會過濾掉）
  adorn_pct_formatting(digits = 1)                      # 格式化為 "16.0%" 這種格式


# 移除 Total 行
gender_long <- gender_tab %>%
  filter(gender != "Total") %>%
  pivot_longer(cols = -gender, names_to = "attrition_flag", values_to = "percent")

# 加上筆數以顯示 bar 高度
gender_counts <- raw_data %>%
  count(gender, attrition_flag)

# 合併百分比與筆數
gender_plot_data <- left_join(gender_counts, gender_long, by = c("gender", "attrition_flag"))

# 繪圖
ggplot(gender_plot_data, aes(x = gender, y = n, fill = attrition_flag)) +
  geom_col(position = "dodge") +
  geom_text(aes(label = percent),
            position = position_dodge(width = 0.9), vjust = -0.3, size = 4) +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed")) +
  labs(
    title = "Churn Rate by Gender",
    x = "Gender",
    y = "Number of Customers"
  ) +
  theme_minimal() +
  theme(legend.title = element_blank(), plot.title = element_text(hjust = 0.5))

```

#### customer age

```{r}
ggplot(raw_data, aes(x = attrition_flag, y = customer_age, fill = attrition_flag)) +
  geom_boxplot(width = 0.5, alpha = 0.8, outlier.shape = 16, outlier.size = 2) +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed")) +
  labs(
    title = "Distribution of Customer Age by Attrition",
    subtitle = "Comparing age distribution of churned vs existing customers",
    x = "Customer Status",
    y = "Customer Age"
  ) +
  theme_minimal() +
  theme(
    legend.position = "none",
    plot.title = element_text(hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5)
  )

```


```{r}
ggplot(raw_data, aes(x = customer_age, fill = attrition_flag)) +
  geom_histogram(position = "identity", alpha = 0.6, bins = 30, color = "white") +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed"), labels = c("Attrited", "Existing")) +
  labs(
    title = "Distribution of Customer Age by Attrition",
    x = "Customer Age",
    y = "Count",
    fill = "Customer Status"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.title = element_text(size = 11)
  )

```

```{r}
# Step 1: 分箱
raw_data <- raw_data %>%
  mutate(age_group = cut(customer_age,
                         breaks = c(20, 30, 40, 50, 60, 70),
                         labels = c("20–29", "30–39", "40–49", "50–59", "60–69")))

# Step 2: 百分比與筆數
library(janitor)

age_tab <- raw_data %>%
  tabyl(age_group, attrition_flag) %>%
  adorn_percentages("row") %>%
  adorn_totals("row") %>%
  adorn_pct_formatting(digits = 1)

age_long <- age_tab %>%
  filter(age_group != "Total") %>%
  pivot_longer(cols = -age_group, names_to = "attrition_flag", values_to = "percent")

age_counts <- raw_data %>%
  count(age_group, attrition_flag)

age_plot_data <- left_join(age_counts, age_long, by = c("age_group", "attrition_flag"))

# Step 3: 繪圖
ggplot(age_plot_data, aes(x = age_group, y = n, fill = attrition_flag)) +
  geom_col(position = "dodge") +
  geom_text(aes(label = percent),
            position = position_dodge(width = 0.9), vjust = -0.3, size = 4) +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed")) +
  labs(
    title = "Churn Rate by Age Group",
    subtitle = "Grouped by customer_age",
    x = "Age Group",
    y = "Number of Customers"
  ) +
  theme_minimal() +
  theme(
    legend.title = element_blank(),
    plot.title = element_text(hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5)
  )

```


#### education_level

```{r,message=FALSE,echo=FALSE}
# 建交叉表與百分比
edu_tab <- raw_data %>%
  tabyl(education_level, attrition_flag) %>%
  adorn_percentages("row") %>%
  adorn_totals("row") %>%
  adorn_pct_formatting(digits = 1)

edu_long <- edu_tab %>%
  filter(education_level != "Total") %>%
  pivot_longer(cols = -education_level, names_to = "attrition_flag", values_to = "percent")

edu_counts <- raw_data %>%
  count(education_level, attrition_flag)

edu_plot_data <- left_join(edu_counts, edu_long, by = c("education_level", "attrition_flag"))

# 畫圖
ggplot(edu_plot_data, aes(x = education_level, y = n, fill = attrition_flag)) +
  geom_col(position = "dodge") +
  geom_text(aes(label = percent),
            position = position_dodge(width = 0.9), vjust = -0.3, size = 4) +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed")) +
  labs(
    title = "Customer Churn by Education Level",
    subtitle = "Based on 10,127 credit card customers",
    x = "Education Level", y = "Number of Customers"
  ) +
  theme_minimal() +
  theme(legend.title = element_blank(),
        plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))

```


#### marital_status 

```{r,message=FALSE,echo=FALSE}
mar_tab <- raw_data %>%
  tabyl(marital_status, attrition_flag) %>%
  adorn_percentages("row") %>%
  adorn_totals("row") %>%
  adorn_pct_formatting(digits = 1)

mar_long <- mar_tab %>%
  filter(marital_status != "Total") %>%
  pivot_longer(cols = -marital_status, names_to = "attrition_flag", values_to = "percent")

mar_counts <- raw_data %>%
  count(marital_status, attrition_flag)

mar_plot_data <- left_join(mar_counts, mar_long, by = c("marital_status", "attrition_flag"))

ggplot(mar_plot_data, aes(x = marital_status, y = n, fill = attrition_flag)) +
  geom_col(position = "dodge") +
  geom_text(aes(label = percent),
            position = position_dodge(width = 0.9), vjust = -0.3, size = 4) +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed")) +
  labs(
    title = "Customer Churn by Marital Status",
    subtitle = "Based on 10,127 credit card customers",
    x = "Marital Status", y = "Number of Customers"
  ) +
  theme_minimal() +
  theme(legend.title = element_blank(),
        plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))

```


#### dependent

```{r,message=FALSE,echo=FALSE}
dep_tab <- raw_data %>%
  tabyl(dependent_count, attrition_flag) %>%
  adorn_percentages("row") %>%
  adorn_totals("row") %>%
  adorn_pct_formatting(digits = 1)

dep_long <- dep_tab %>%
  filter(dependent_count != "Total") %>%
  pivot_longer(cols = -dependent_count, names_to = "attrition_flag", values_to = "percent")

dep_counts <- raw_data %>%
  count(dependent_count, attrition_flag)

dep_counts <- dep_counts %>%
  mutate(dependent_count = as.character(dependent_count))


dep_plot_data <- left_join(dep_counts, dep_long, by = c("dependent_count", "attrition_flag"))

ggplot(dep_plot_data, aes(x = as.factor(dependent_count), y = n, fill = attrition_flag)) +
  geom_col(position = "dodge") +
  geom_text(aes(label = percent),
            position = position_dodge(width = 0.9), vjust = -0.3, size = 4) +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed")) +
  labs(
    title = "Customer Churn by Number of Dependents",
    subtitle = "Based on 10,127 credit card customers",
    x = "Number of Dependents", y = "Number of Customers"
  ) +
  theme_minimal() +
  theme(legend.title = element_blank(),
        plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))

```







# 客戶活躍度（Customer Activity Level）


  



#### total_trans_ct (年交易次數 會影響流失嗎?)

```{r}
ggplot(raw_data, aes(x = attrition_flag, y = total_trans_ct, fill = attrition_flag)) +
  geom_boxplot(width = 0.5, alpha = 0.8, outlier.shape = 16, outlier.size = 2) +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed")) +
  labs(
    title = "Distribution of Total Transactions by Customer Status",
    subtitle = "Customers who churned tend to have fewer transactions",
    x = "Customer Status",
    y = "Total Transactions (12 months)"
  ) +
  theme_minimal() +
  theme(legend.position = "none",
        plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))
```

```{r}
library(ggplot2)
library(dplyr)

ggplot(raw_data, aes(x = total_trans_ct , fill = attrition_flag)) +
  geom_histogram(position = "identity", alpha = 0.6, bins = 30, color = "white") +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed"), labels = c("Attrited", "Existing")) +
  labs(
    title = "Distribution of total_trans_ct by Attrition",
    x = "total_trans_ct",
    y = "Count",
    fill = "Customer Status"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.title = element_text(size = 11)
  )

```

流失顧客的年交易次數明顯較少

中位數大約在 40 次左右，而非流失顧客接近 75 次。

流失者的交易活躍程度集中且低

他們的行為比較一致，大多數集中在 30–60 次之間。

非流失顧客交易行為變異較大

分布往右偏，有很多高頻交易者（超過 100 次也不少）。


低活躍是流失的明確預警信號

顧客的活躍度（交易次數）越低，越可能流失。

可以用交易次數來設定干預策略

例如設一個門檻：「12 個月內交易低於 40 次」的顧客列為高風險名單。

模型建構上，這是一個強變數

total_trans_ct 不只是數值變數，更具有明顯區分力，有助於提升模型準確度。

####  total_ct_chng_q4_q1 (第4季對第1季的交易頻率變化率)



```{r}
ggplot(raw_data, aes(x = attrition_flag, y = total_ct_chng_q4_q1, fill = attrition_flag)) +
  geom_boxplot(width = 0.5, alpha = 0.8, outlier.shape = 16, outlier.size = 2) +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed")) +
  labs(
    title = "Change in Transaction Count (Q4 vs Q1)",
    subtitle = "Customers with declining activity may be at risk of churn",
    x = "Customer Status",
    y = "Transaction Count Change (Q4 - Q1)"
  ) +
  theme_minimal() +
  theme(legend.position = "none",
        plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))

```

```{r}
ggplot(raw_data, aes(x = total_ct_chng_q4_q1, fill = attrition_flag)) +
  geom_histogram(position = "identity", alpha = 0.6, bins = 30, color = "white") +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed"), labels = c("Attrited", "Existing")) +
  labs(
    title = "Distribution of total_ct_chng_q4_q1 by Attrition",
    x = "total_ct_chng_q4_q1k",
    y = "Count",
    fill = "Customer Status"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.title = element_text(size = 11)
  )

```
total_ct_chng_q4_q1（交易次數變化率）在 attrited 和 existing 顧客之間
沒有明顯的差異


#### total_amt_chng_q4_q1 交易金額變化率

```{r}
ggplot(raw_data, aes(x = attrition_flag, y = total_amt_chng_q4_q1, fill = attrition_flag)) +
  geom_boxplot(width = 0.5, alpha = 0.8, outlier.shape = 16, outlier.size = 2) +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed")) +
  labs(
    title = "Change in Transaction Amount (Q4 vs Q1) by Customer Status",
    subtitle = "Churned customers may reduce their spending before leaving",
    x = "Customer Status",
    y = "Q4 vs Q1 Amount Change Ratio"
  ) +
  theme_minimal() +
  theme(legend.position = "none",
        plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))

```





```{r}
ggplot(raw_data, aes(x = total_amt_chng_q4_q1, fill = attrition_flag)) +
  geom_histogram(position = "identity", alpha = 0.6, bins = 30, color = "white") +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed"), labels = c("Attrited", "Existing")) +
  labs(
    title = "Distribution of total_amt_chng_q4_q1 by Attrition",
    x = "total_amt_chng_q4_q1",
    y = "Count",
    fill = "Customer Status"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.title = element_text(size = 11)
  )

```




total_amt_chng_q4_q1（交易金額變化率）在 attrited 和 existing 之間的差異也很小。





#### total_trans_amt	年度交易總金額




```{r}
ggplot(raw_data, aes(x = attrition_flag, y = total_trans_amt, fill = attrition_flag)) +
  geom_boxplot(width = 0.5, alpha = 0.8, outlier.shape = 16, outlier.size = 2) +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed")) +
  labs(
    title = "total_trans_amt",
    subtitle = "total_trans_amt",
    x = "Customer Status",
    y = "Q4 vs Q1 Amount Change Ratio"
  ) +
  theme_minimal() +
  theme(legend.position = "none",
        plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))

```





```{r}
ggplot(raw_data, aes(x = total_trans_amt, fill = attrition_flag)) +
  geom_histogram(position = "identity", alpha = 0.6, bins = 30, color = "white") +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed"), labels = c("Attrited", "Existing")) +
  labs(
    title = "total_trans_amt",
    x = "total_trans_amt",
    y = "Count",
    fill = "Customer Status"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.title = element_text(size = 11)
  )

```

流失顧客大多集中在低總交易金額（total_trans_amt）區間，
高交易金額客戶幾乎不流失，代表價值客群穩定。

#### 客戶活躍度（Customer Activity Level）小結論

在所有活躍度變數中，**交易金額總量（total_trans_amt）與交易次數（total_trans_ct）**對於預測顧客是否會流失最具區辨力，建議作為建模與策略設計的主要變數。





---

# 信用使用行為 Credit Usage Behavior 


#### avg_utilization_ratio	顧客平均信用卡利用率（餘額／額度）使用「多少比例」的額度

```{r}
ggplot(raw_data, aes(x = attrition_flag, y = avg_utilization_ratio, fill = attrition_flag)) +
  geom_boxplot(width = 0.5, alpha = 0.8, outlier.shape = 16, outlier.size = 2) +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed")) +
  labs(
    title = "avg_utilization_ratio",
    subtitle = "avg_utilization_ratio",
    x = "Customer Status",
    y = "avg_utilization_ratio"
  ) +
  theme_minimal() +
  theme(legend.position = "none",
        plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))

```



```{r}
ggplot(raw_data, aes(x = avg_utilization_ratio, fill = attrition_flag)) +
  geom_histogram(position = "identity", alpha = 0.6, bins = 30, color = "white") +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed"), labels = c("Attrited", "Existing")) +
  labs(
    title = "avg_utilization_ratio",
    x = "avg_utilization_ratio",
    y = "Count",
    fill = "Customer Status"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.title = element_text(size = 11)
  )

```


```{r}
library(dplyr)

raw_data <- raw_data %>%
  mutate(util_bin = cut(avg_utilization_ratio,
                        breaks = c(0, 0.1, 0.3, 0.5, 0.7, 1.0),
                        labels = c("0–0.1", "0.1–0.3", "0.3–0.5", "0.5–0.7", "0.7–1.0"),
                        right = TRUE))



library(janitor)

util_tab <- raw_data %>%
  tabyl(util_bin, attrition_flag) %>%
  adorn_percentages("row") %>%
  adorn_totals("row") %>%
  adorn_pct_formatting(digits = 1)

print(util_tab)  # 可先檢查表格



library(tidyr)
library(ggplot2)

# 準備長格式資料（移除 Total row）
util_long <- util_tab %>%
  filter(util_bin != "Total") %>%
  pivot_longer(cols = -util_bin,
               names_to = "attrition_flag",
               values_to = "percent")

# 繪製分組條圖
ggplot(util_long, aes(x = util_bin, y = percent, fill = attrition_flag)) +
  geom_col(position = "dodge") +
  geom_text(aes(label = percent),
            position = position_dodge(width = 0.9),
            vjust = -0.3, size = 4) +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed"),
                    labels = c("Attrited", "Existing")) +
  labs(
    title = "Churn Rate by Credit Utilization Level",
    subtitle = "Grouped by average utilization ratio",
    x = "Utilization Ratio (Binned)",
    y = "Percentage (%)",
    fill = "Customer Status"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))


```


顧客平均信用卡利用率（餘額／額度）

利用率高（→ 接近 1）	                  利用率低（→ 接近 0）
幾乎把信用額度用滿了（可能有資金壓力）	使用額度相對保守（資金較穩定）
財務風險高 → 可能將關帳或流失	          忠誠或保守型使用者
可能代表傾向提前關卡還款、風險高	      低風險核心客群


因為在許多信貸或信用風險領域，人們會直覺地認為：

「信用卡使用率高 = 財務壓力大 = 比較容易關帳或流失」

但你剛剛畫的圖卻顯示：

真正流失的客戶，反而是那些「低信用卡利用率」的客戶。

這就是所謂的「反直覺（counterintuitive）」

McKinsey（2020）：指出高頻交易客戶的留存率比低使用者高 40–60%。

銀行客戶終生價值模型（CLV）：高使用者 ≈ 高 CLV → retention investment priority。

**行為式分群（Behavioral Segmentation）**常用 utilization ratio 當作 engagement proxy





avg_utilization_ratio（平均信用卡利用率）高的客戶反而不容易流失，
Attrited 客戶大多集中在低利用率區域。

在銀行業屬於常態，符合實務經驗與既有研究


#### credit_limit 核定信用額度



```{r}
ggplot(raw_data, aes(x = attrition_flag, y = credit_limit, fill = attrition_flag)) +
  geom_boxplot(width = 0.5, alpha = 0.8, outlier.shape = 16, outlier.size = 2) +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed")) +
  labs(
    title = "credit_limit",
    subtitle = "credit_limit",
    x = "Customer Status",
    y = "avg_utilization_ratio"
  ) +
  theme_minimal() +
  theme(legend.position = "none",
        plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))

```



```{r}
ggplot(raw_data, aes(x = credit_limit, fill = attrition_flag)) +
  geom_histogram(position = "identity", alpha = 0.6, bins = 30, color = "white") +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed"), labels = c("Attrited", "Existing")) +
  labs(
    title = "credit_limit",
    x = "credit_limit",
    y = "Count",
    fill = "Customer Status"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.title = element_text(size = 11)
  )

```


```{r}
library(dplyr)

raw_data <- raw_data %>%
  mutate(limit_bin = cut(credit_limit,
                         breaks = c(0, 5000, 10000, 20000, 30000, Inf),
                         labels = c("≤5K", "5K–10K", "10K–20K", "20K–30K", ">30K"),
                         right = TRUE))


library(janitor)

limit_tab <- raw_data %>%
  tabyl(limit_bin, attrition_flag) %>%
  adorn_percentages("row") %>%
  adorn_totals("row") %>%
  adorn_pct_formatting(digits = 1)

print(limit_tab)  # 可先檢查表格

library(tidyr)
library(ggplot2)

# 移除總計列
limit_long <- limit_tab %>%
  filter(limit_bin != "Total") %>%
  pivot_longer(cols = -limit_bin,
               names_to = "attrition_flag",
               values_to = "percent")

# 繪製分箱 Churn Rate 圖
ggplot(limit_long, aes(x = limit_bin, y = percent, fill = attrition_flag)) +
  geom_col(position = "dodge") +
  geom_text(aes(label = percent),
            position = position_dodge(width = 0.9), vjust = -0.3, size = 4) +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed"),
                    labels = c("Attrited", "Existing")) +
  labs(
    title = "Churn Rate by Credit Limit Bracket",
    subtitle = "Grouped by approved credit limit",
    x = "Credit Limit Range",
    y = "Percentage (%)",
    fill = "Customer Status"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))

```




信用額度在這份資料中不是一個有明顯區辨力的變數，流失客戶遍佈各額度區間，沒有特定「高額留存、低額流失」的趨勢。這個變數可以保留在模型中觀察交互效應，但在單一解釋上意義有限


低額度客戶比較多流失，這到底算不算一個夠強的發現？



這個發現有可能是「結構性分布」，而非「流失傾向」。
✔ 是的，低額度區間的確有較多流失者，但這有兩種可能解釋：
這區本來就人最多 → 絕對數高很正常
→ 也就是母體基數大，不代表風險高

沒有明顯「額度越低 → 流失率越高」的趨勢
→ 如果要當作強發現，應該在分箱後觀察到「低額度區的流失比例（百分比）特別高



✅ 觀察 1：整體變化趨勢小
流失率在不同額度區間間略有起伏，但整體差異幅度不大（在 12.7%～17.3% 間浮動）。

並沒有呈現「信用額度越低 → 流失率越高」的單調遞增趨勢。

✅ 觀察 2：極端高與極端低都有略高流失
≤5K 和 >30K 的區間流失率偏高（17.3%、16.2%）。

但中間區間（10K–30K）則有較低流失率（約 12.7%–14.4%）。


#### avg_open_to_buy 可動用額度 還能刷多少




```{r}
ggplot(raw_data, aes(x = attrition_flag, y = avg_open_to_buy, fill = attrition_flag)) +
  geom_boxplot(width = 0.5, alpha = 0.8, outlier.shape = 16, outlier.size = 2) +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed")) +
  labs(
    title = "avg_open_to_buy",
    subtitle = "avg_open_to_buy",
    x = "Customer Status",
    y = "avg_utilization_ratio"
  ) +
  theme_minimal() +
  theme(legend.position = "none",
        plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))

```



```{r}
ggplot(raw_data, aes(x = avg_open_to_buy, fill = attrition_flag)) +
  geom_histogram(position = "identity", alpha = 0.6, bins = 30, color = "white") +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed"), labels = c("Attrited", "Existing")) +
  labs(
    title = "avg_open_to_buy",
    x = "avg_open_to_buy",
    y = "Count",
    fill = "Customer Status"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.title = element_text(size = 11)
  )

```


和 avg_utilization_ratio 相比，avg_open_to_buy 辨別力略低。

但仍能提供一個補充角度：Attrited 客戶的可用空間也偏少，但不是最明顯的分界。

實務上，這個變數可能適合用於模型中與其他信用額度行為變數（如 credit_limit、utilization）共同解釋，而非單獨用來預測。

#### total_revolving_bal 客戶的信用卡未繳餘額


```{r}
ggplot(raw_data, aes(x = attrition_flag, y = total_revolving_bal, fill = attrition_flag)) +
  geom_boxplot(width = 0.5, alpha = 0.8, outlier.shape = 16, outlier.size = 2) +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed")) +
  labs(
    title = "total_revolving_bal",
    subtitle = "total_revolving_bal",
    x = "Customer Status",
    y = "avg_utilization_ratio"
  ) +
  theme_minimal() +
  theme(legend.position = "none",
        plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))

```



```{r}
ggplot(raw_data, aes(x = total_revolving_bal, fill = attrition_flag)) +
  geom_histogram(position = "identity", alpha = 0.6, bins = 30, color = "white") +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed"), labels = c("Attrited", "Existing")) +
  labs(
    title = "total_revolving_bal",
    x = "total_revolving_bal",
    y = "Count",
    fill = "Customer Status"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.title = element_text(size = 11)
  )

```


total_revolving_bal 絕對值得納入模型，因為它明顯揭示流失客戶有「不用卡」的行為，和 total_trans_ct & utilization_ratio 一致。





#### 信用使用行為 Credit Usage Behavior 小結論

| 指標 | 資訊價值 | 解讀重點 |
|------|------------|----------|
| `total_revolving_bal` | ✅ 高 | Attrited 客戶多為「沒在用、沒欠錢」，是非活躍跡象 |
| `avg_utilization_ratio` | ✅ 高 | 標準化使用率低，更清楚顯示「不用卡」 |
| `avg_open_to_buy` | ⚠️ 中 | 因為額度不同，解釋略模糊 |
| `credit_limit` | ⚠️ 中 | 結構變數，不直接反映行為 |



# Account Relationship Strength





#### months_on_book（帳戶持有月數）

```{r}
# Boxplot
ggplot(raw_data, aes(x = attrition_flag, y = months_on_book, fill = attrition_flag)) +
  geom_boxplot(width = 0.5, alpha = 0.8, outlier.shape = 16, outlier.size = 2) +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed")) +
  labs(
    title = "months_on_book",
    subtitle = "Duration of Customer Relationship (in months)",
    x = "Customer Status",
    y = "Months on Book"
  ) +
  theme_minimal() +
  theme(legend.position = "none",
        plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))

# Histogram
ggplot(raw_data, aes(x = months_on_book, fill = attrition_flag)) +
  geom_histogram(position = "identity", alpha = 0.6, bins = 30, color = "white") +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed"), labels = c("Attrited", "Existing")) +
  labs(
    title = "months_on_book",
    x = "Months on Book",
    y = "Count",
    fill = "Customer Status"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.title = element_text(size = 11)
  )

```



#### total_relationship_count

```{r}
# Boxplot
ggplot(raw_data, aes(x = attrition_flag, y = total_relationship_count, fill = attrition_flag)) +
  geom_boxplot(width = 0.5, alpha = 0.8, outlier.shape = 16, outlier.size = 2) +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed")) +
  labs(
    title = "total_relationship_count",
    subtitle = "Number of Bank Products Held by Customer",
    x = "Customer Status",
    y = "Relationship Count"
  ) +
  theme_minimal() +
  theme(legend.position = "none",
        plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))

# Histogram
ggplot(raw_data, aes(x = total_relationship_count, fill = attrition_flag)) +
  geom_histogram(position = "identity", alpha = 0.6, bins = 6, color = "white") +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed"), labels = c("Attrited", "Existing")) +
  labs(
    title = "total_relationship_count",
    x = "Number of Bank Products",
    y = "Count",
    fill = "Customer Status"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.title = element_text(size = 11)
  )





```





#### months_inactive_12_mon

```{r}
# Boxplot
ggplot(raw_data, aes(x = attrition_flag, y = months_inactive_12_mon, fill = attrition_flag)) +
  geom_boxplot(width = 0.5, alpha = 0.8, outlier.shape = 16, outlier.size = 2) +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed")) +
  labs(
    title = "months_inactive_12_mon",
    subtitle = "Inactive Months in the Last Year",
    x = "Customer Status",
    y = "Inactive Months"
  ) +
  theme_minimal() +
  theme(legend.position = "none",
        plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))

# Histogram
ggplot(raw_data, aes(x = months_inactive_12_mon, fill = attrition_flag)) +
  geom_histogram(position = "identity", alpha = 0.6, bins = 6, color = "white") +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed"), labels = c("Attrited", "Existing")) +
  labs(
    title = "months_inactive_12_mon",
    x = "Inactive Months (past 12)",
    y = "Count",
    fill = "Customer Status"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.title = element_text(size = 11)
  )

```





#### contacts_count_12_mon

```{r}
# Boxplot
ggplot(raw_data, aes(x = attrition_flag, y = contacts_count_12_mon, fill = attrition_flag)) +
  geom_boxplot(width = 0.5, alpha = 0.8, outlier.shape = 16, outlier.size = 2) +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed")) +
  labs(
    title = "contacts_count_12_mon",
    subtitle = "Customer Service Contacts in Last 12 Months",
    x = "Customer Status",
    y = "Contact Count"
  ) +
  theme_minimal() +
  theme(legend.position = "none",
        plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))

# Histogram
ggplot(raw_data, aes(x = contacts_count_12_mon, fill = attrition_flag)) +
  geom_histogram(position = "identity", alpha = 0.6, bins = 6, color = "white") +
  scale_fill_manual(values = c("#004c6d", "#a7c6ed"), labels = c("Attrited", "Existing")) +
  labs(
    title = "contacts_count_12_mon",
    x = "Number of Contacts (past 12)",
    y = "Count",
    fill = "Customer Status"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.title = element_text(size = 11)
  )

```

🔹 1. months_on_book
代表意義：表示客戶與銀行維持關係的時間（越長代表忠誠度可能越高）
觀察重點：

此變數在兩群之間幾乎對稱，說明「關係持續時間」可能不是主要的流失驅動因子。

某個月份（如 36 個月）明顯出現尖峰 → 應考慮是否有「合約週期」或「系統性更新」導致這個月數特別多。

🔹 2. total_relationship_count
代表意義：一位客戶在該行擁有多少金融產品，通常代表黏著度與價值貢獻
觀察重點：

擁有較多產品的客戶，流失率相對較低。

流失客戶集中在 1–3 個產品區間，暗示「關係淺薄」者更易流失。

🔹 3. months_inactive_12_mon
代表意義：過去一年中，有多少個月沒有使用過帳戶。這是一個先行指標（leading indicator）。
觀察重點：

流失客戶在 3–6 個月無活動的比例明顯偏高。

可用來設計預測模型的 early warning signal。

🔹 4. contacts_count_12_mon
代表意義：過去一年聯絡客服的次數。可能是抱怨、問題、申訴等。
觀察重點：

流失客戶的聯絡頻率略高（特別是 4–6 次）。

與服務滿意度或問題處理效率有關 → 可作為間接服務品質指標。


#### Account Relationship Strength 小結

| 變數 | 重要性判斷 | 原因 |
|------|--------------|------|
| `months_on_book` | 低 | 沒有明顯差異 |
| `total_relationship_count` | 中等 | 流失率與產品數量明顯呈現負相關 |
| `months_inactive_12_mon` | 高 | 活躍度下降是流失的重要指標 |
| `contacts_count_12_mon` | 中等偏高 | 客服聯繫次數可能反映不滿意，與流失有潛在關聯 |

# radar plot

```{r}
library(dplyr)
library(fmsb)

# Step 1: 整理資料（與之前相同）
radar_df <- raw_data %>%
  mutate(
    high_trans = if_else(total_trans_ct > median(total_trans_ct, na.rm = TRUE), 1, 0),
    amt_change_high = if_else(total_amt_chng_q4_q1 > 1.5, 1, 0),
    high_util = if_else(avg_utilization_ratio > 0.3, 1, 0),
    high_revolve_bal = if_else(total_revolving_bal > 1000, 1, 0),
    frequent_contact = if_else(contacts_count_12_mon > 2, 1, 0)
  ) %>%
  select(attrition_flag, high_trans, amt_change_high, high_util, high_revolve_bal, frequent_contact)

radar_data <- radar_df %>%
  group_by(attrition_flag) %>%
  summarise(across(everything(), ~ mean(.x, na.rm = TRUE))) %>%
  as.data.frame()

rownames(radar_data) <- radar_data$attrition_flag
radar_data <- radar_data[, -1]
radar_data <- rbind(rep(1, ncol(radar_data)), rep(0, ncol(radar_data)), radar_data)

# Step 2: 設定美化樣式
colors_border <- c(rgb(0.2, 0.5, 0.5, 0.9), rgb(0.8, 0.2, 0.5, 0.9))
colors_fill <- c(rgb(0.2, 0.5, 0.5, 0.4), rgb(0.8, 0.2, 0.5, 0.4))

# Step 3: 畫圖
radarchart(radar_data,
           axistype = 1,
           pcol = colors_border,
           pfcol = colors_fill,
           plwd = 4,
           plty = 1,
           cglcol = "grey", 
           cglty = 1, 
           axislabcol = "grey", 
           cglwd = 0.8,
           vlcex = 1.1
)

# Step 4: 圖例
legend(x = 0.7, y = 1,
       legend = c("Existing Customer", "Attrited Customer"),
       bty = "n", pch = 20, col = colors_fill,
       text.col = "grey20", cex = 1.2, pt.cex = 3)


```


```{r}
library(dplyr)
library(fmsb)

# Step 1: 準備資料與二元變數
radar_df <- raw_data %>%
  mutate(
    high_trans = if_else(total_trans_ct > median(total_trans_ct, na.rm = TRUE), 1, 0),
    amt_change_high = if_else(total_amt_chng_q4_q1 > 1.5, 1, 0),
    high_util = if_else(avg_utilization_ratio > 0.3, 1, 0),
    high_revolve_bal = if_else(total_revolving_bal > 1000, 1, 0),
    frequent_contact = if_else(contacts_count_12_mon > 2, 1, 0)
  ) %>%
  select(attrition_flag, high_trans, amt_change_high, high_util, high_revolve_bal, frequent_contact)

# Step 2: 計算平均值
radar_data <- radar_df %>%
  group_by(attrition_flag) %>%
  summarise(across(everything(), ~ mean(.x, na.rm = TRUE))) %>%
  as.data.frame()

# Step 3: 建立 radar 資料
rownames(radar_data) <- radar_data$attrition_flag
radar_data <- radar_data[, -1]
radar_data <- rbind(rep(1, ncol(radar_data)), rep(0, ncol(radar_data)), radar_data)

# Step 4: 高質感雷達圖
colors_border <- c("#1f77b4", "#d62728")      # 線條顏色
colors_fill   <- c("#1f77b4AA", "#d62728AA")  # 半透明填色

radarchart(radar_data,
           axistype = 1,
           pcol = colors_border,
           pfcol = colors_fill,
           plwd = 2,
           plty = 1,
           cglcol = "grey",
           cglty = 1,
           cglwd = 0.8,
           axislabcol = "black",
           vlcex = 1.1,
           title = "Radar Chart: Customer Behavioral Profile")

legend(x = "topright",
       legend = c("Existing Customer", "Attrited Customer"),
       col = colors_border,
       lty = 1,
       lwd = 2,
       bty = "n")

```


```{r}
library(dplyr)
library(ggplot2)

# Step 1: 建立分類與五個指標（與之前相同）
lollipop_data <- raw_data %>%
  mutate(
    high_trans = if_else(total_trans_ct > median(total_trans_ct, na.rm = TRUE), 1, 0),
    amt_change_high = if_else(total_amt_chng_q4_q1 > 1.5, 1, 0),
    high_util = if_else(avg_utilization_ratio > 0.3, 1, 0),
    high_revolve_bal = if_else(total_revolving_bal > 1000, 1, 0),
    frequent_contact = if_else(contacts_count_12_mon > 2, 1, 0)
  ) %>%
  select(attrition_flag, high_trans, amt_change_high, high_util, high_revolve_bal, frequent_contact)

# Step 2: 計算兩組群體的平均比例
lollipop_summary <- lollipop_data %>%
  group_by(attrition_flag) %>%
  summarise(across(everything(), ~ mean(.x, na.rm = TRUE))) %>%
  pivot_longer(cols = -attrition_flag, names_to = "feature", values_to = "value") %>%
  pivot_wider(names_from = attrition_flag, values_from = value) %>%
  rename(existing = `Existing Customer`, attrited = `Attrited Customer`)

# Step 3: 繪製 Lollipop Plot
ggplot(lollipop_summary) +
  geom_segment(aes(x = feature, xend = feature, y = existing, yend = attrited), color = "grey") +
  geom_point(aes(x = feature, y = existing), color = "#1f77b4", size = 4) +
  geom_point(aes(x = feature, y = attrited), color = "#d62728", size = 4, alpha = 0.8) +
  coord_flip() +
  labs(
    title = "Customer Behavior Comparison: Existing vs Attrited",
    y = "Proportion (binary feature = 1)",
    x = NULL
  ) +
  theme_minimal() +
  theme(
    panel.grid.minor.y = element_blank(),
    panel.grid.major.y = element_blank(),
    axis.text = element_text(size = 12),
    plot.title = element_text(size = 15, face = "bold")
  )

```



```{r}
skim(raw_data)
names(train_data2)  # 看目前資料集欄位名中有沒有 "util_bin"

```

```{r,message=FALSE}
raw_data<-read_csv(here("Data","bank_churners.csv")) %>% 
  clean_names()

```



# Data split

```{r}
set.seed(47969938)
data_split2<- initial_split(raw_data, prop = 0.8, strata = attrition_flag)
train_data2<- training(data_split2)
test_data2 <- testing(data_split2)
# Cross-validation folds
cross_validation_folds2 <- vfold_cv(train_data2, v = 10, strata = attrition_flag)

```



# Logistic base model - clean version

```{r}
# Define model
base_logistic_spec2 <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")

# Define recipe ---------------------------------------------------------------
logistic_recipe2 <- recipe(attrition_flag ~ ., data = train_data2) |> 
  step_other(all_nominal_predictors(), threshold = 0.05) |>  # 1. 合併小眾類別
  step_zv(all_predictors()) |>                               # 2. 移除常數或零變異變數
  step_corr(all_numeric_predictors(), threshold = 0.7) |>    # 3. 剃掉高相關數值變數
  step_dummy(all_nominal_predictors()) |>                    # 4. 把類別轉成 0/1 dummy
  step_normalize(all_numeric_predictors())                   # 5. 標準化數值變數


# Create workflow -------------------------------------------------------------
base_logistic_wf2 <- workflow() |> 
  add_model(base_logistic_spec2) |> 
  add_recipe(logistic_recipe2)

# Cross-validation: fit_resamples ---------------------------------------------
base_logistic_cv2 <- fit_resamples(
  base_logistic_wf2,
  resamples = cross_validation_folds2,
  metrics = metric_set(roc_auc, accuracy)
)

# Evaluation on cross-validation folds ----------------------------------------
collect_metrics(base_logistic_cv2)

# Last fit: 用 train_data2 fit，predict test_data2
final_base_fit2 <- last_fit(
  base_logistic_wf2,
  split = data_split2,
  metrics = metric_set( # 直接在此擴充指標
    roc_auc, 
    accuracy,
    recall,     # 新增
    precision,  # 新增
    f_meas      # 新增
))

# Collect performance on test set
collect_metrics(final_base_fit2)



```


```{r}
# 1. prep recipe
logistic_recipe2_prep <- logistic_recipe2 |> prep()

# 2. check剃除的變數
tidy(logistic_recipe2_prep, number = 3) |> 
  filter(terms != "(Intercept)")

```
```{r}
tidy(logistic_recipe2_prep)

tidy(logistic_recipe2_prep, number = 4) |> 
  filter(terms != "(Intercept)")
```


```{r}
# 先載好必要的套件
library(vip)

# 畫 Variable Importance Plot
final_base_fit2 %>%
  extract_fit_parsnip() %>%
  vip(num_features = 20)  # 只列出前20重要的變數

```

# 類別分布 (流失比例)

```{r}
table(train_data2$attrition_flag)
prop.table(table(train_data2$attrition_flag))
```




# 混淆矩陣

```{r}
final_base_fit2 %>%
  collect_predictions() %>%
  conf_mat(truth = attrition_flag, estimate = .pred_class)
```















# Ridge Logistic Regression (mixture = 0) - clean version


```{r}
# Ridge Logistic Regression (mixture = 0) - clean version

# Define model
ridge_spec2 <- logistic_reg(
  penalty = tune(),   # penalty要tune
  mixture = 0         # mixture = 0 = Ridge
) %>%
  set_engine("glmnet") %>%
  set_mode("classification")

# Create workflow
ridge_wf2 <- workflow() %>%
  add_model(ridge_spec2) %>%
  add_recipe(logistic_recipe2)   # <--- 用乾淨版recipe2

# Define tuning grid
ridge_grid2 <- grid_regular(
  penalty(range = c(-4, 0)),
  levels = 30
)

# Tuning
ridge_tune2 <- tune_grid(
  ridge_wf2,
  resamples = cross_validation_folds2,  # <--- 用乾淨版folds2
  grid = ridge_grid2,
  metrics = metric_set(roc_auc, accuracy)
)

# Select best model
best_ridge2 <- select_best(ridge_tune2, metric = "roc_auc")

# Finalize workflow
final_ridge_wf2 <- finalize_workflow(ridge_wf2, best_ridge2)

# Last fit
final_ridge_fit2 <- last_fit(
  final_ridge_wf2,
  split = data_split2,   # <--- 用乾淨版split2
  metrics = metric_set( # 直接在此擴充指標
    roc_auc, 
    accuracy,
    recall,     # 新增
    precision,  # 新增
    f_meas      # 新增
))

# Collect metrics
collect_metrics(final_ridge_fit2)

```



# Lasso Logistic Regression (mixture = 1) - clean version


```{r}
# Lasso Logistic Regression (mixture = 1) - clean version

# Define model
lasso_spec2 <- logistic_reg(
  penalty = tune(),   # penalty要tune
  mixture = 1         # mixture = 1 = Lasso
) %>%
  set_engine("glmnet") %>%
  set_mode("classification")

# Create workflow
lasso_wf2 <- workflow() %>%
  add_model(lasso_spec2) %>%
  add_recipe(logistic_recipe2)  # 用乾淨版recipe2

# Define tuning grid
lasso_grid2 <- grid_regular(
  penalty(range = c(-4, 0)),
  levels = 30
)

# Tuning
lasso_tune2 <- tune_grid(
  lasso_wf2,
  resamples = cross_validation_folds2,  # 用乾淨版 folds2
  grid = lasso_grid2,
  metrics = metric_set(roc_auc, accuracy)
)

# Select best model
best_lasso2 <- select_best(lasso_tune2, metric = "roc_auc")

# Finalize workflow
final_lasso_wf2 <- finalize_workflow(lasso_wf2, best_lasso2)

# Last fit
final_lasso_fit2 <- last_fit(
  final_lasso_wf2,
  split = data_split2,   # 用乾淨版 split2
  metrics = metric_set( # 直接在此擴充指標
    roc_auc, 
    accuracy,
    recall,     # 新增
    precision,  # 新增
    f_meas      # 新增
))

# Collect metrics
collect_metrics(final_lasso_fit2)

```




# Elastic Net Logistic Regression - clean version

```{r}
# Elastic Net Logistic Regression - clean version

# Define model
elastic_spec2 <- logistic_reg(
  penalty = tune(),
  mixture = tune()    # Elastic Net要tune mixture
) %>%
  set_engine("glmnet") %>%
  set_mode("classification")

# Create workflow
elastic_wf2 <- workflow() %>%
  add_model(elastic_spec2) %>%
  add_recipe(logistic_recipe2)  # 用乾淨版recipe2

# Define tuning grid
elastic_grid2 <- grid_regular(
  penalty(range = c(-4, 0)),
  mixture(range = c(0, 1)),
  levels = c(20, 5)             # penalty取20點，mixture取5點
)

# Tuning
elastic_tune2 <- tune_grid(
  elastic_wf2,
  resamples = cross_validation_folds2,  # 用乾淨版 folds2
  grid = elastic_grid2,
  metrics = metric_set(roc_auc, accuracy)
)

# Select best model
best_elastic2 <- select_best(elastic_tune2, metric = "roc_auc")

# Finalize workflow
final_elastic_wf2 <- finalize_workflow(elastic_wf2, best_elastic2)

# Last fit
final_elastic_fit2 <- last_fit(
  final_elastic_wf2,
  split = data_split2,  # 用乾淨版 split2
  metrics = metric_set( # 直接在此擴充指標
    roc_auc, 
    accuracy,
    recall,     # 新增
    precision,  # 新增
    f_meas      # 新增
))

# Collect metrics
collect_metrics(final_elastic_fit2)

```



# KNN - clean version

```{r}
# KNN - clean version

# 1.1 Define KNN model
knn_spec2 <- nearest_neighbor(
  neighbors = tune()
) %>%
  set_engine("kknn") %>%
  set_mode("classification")

# 1.2 Define Recipe（記得要normalize）
knn_recipe2 <- recipe(attrition_flag ~ ., data = train_data2) %>%
  step_other(all_nominal_predictors(), threshold = 0.05) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_zv(all_predictors()) %>%
  step_corr(threshold = 0.7) %>%
  step_normalize(all_numeric_predictors())  # KNN一定要normalize！

# 1.3 Create Workflow
knn_wf2 <- workflow() %>%
  add_model(knn_spec2) %>%
  add_recipe(knn_recipe2)

# 1.4 Define Grid
knn_grid2 <- grid_regular(
  neighbors(range = c(3, 50)),
  levels = 10
)

# 1.5 Tune
knn_tuned2 <- tune_grid(
  knn_wf2,
  resamples = cross_validation_folds2,   # 用新的 folds2
  grid = knn_grid2,
  metrics = metric_set(roc_auc, accuracy)
)

# 1.6 Select best
knn_best2 <- select_best(knn_tuned2, metric = "roc_auc")

# 1.7 Finalize
final_knn_wf2 <- finalize_workflow(knn_wf2, knn_best2)

# 1.8 Last Fit
knn_final_fit2 <- last_fit(
  final_knn_wf2,
  split = data_split2,  metrics = metric_set( # 直接在此擴充指標
    roc_auc, 
    accuracy,
    recall,     # 新增
    precision,  # 新增
    f_meas      # 新增
))

# 1.9 Collect metrics
collect_metrics(knn_final_fit2)

```


# Random Forest - clean version

```{r}
# Random Forest - clean version

# 2.1 Define Random Forest model
rf_spec2 <- rand_forest(
  mtry = tune(),
  min_n = tune()
) %>%
  set_engine("ranger", importance = "impurity") %>%
  set_mode("classification")

# 2.2 Define Recipe（RF可以不用normalize）
rf_recipe2 <- recipe(attrition_flag ~ ., data = train_data2) %>%
  step_other(all_nominal_predictors(), threshold = 0.05) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_zv(all_predictors()) %>%
  step_corr(threshold = 0.7)

# 2.3 Create Workflow
rf_wf2 <- workflow() %>%
  add_model(rf_spec2) %>%
  add_recipe(rf_recipe2)

# 2.4 Define Grid
rf_grid2 <- grid_regular(
  mtry(range = c(2, 10)),
  min_n(range = c(5, 30)),
  levels = 5
)

# 2.5 Tune
rf_tuned2 <- tune_grid(
  rf_wf2,
  resamples = cross_validation_folds2,  # 用新的 folds2
  grid = rf_grid2,
  metrics = metric_set(roc_auc, accuracy)
)

# 2.6 Select best
rf_best2 <- select_best(rf_tuned2, metric = "roc_auc")

# 2.7 Finalize
final_rf_wf2 <- finalize_workflow(rf_wf2, rf_best2)

# Last fit
final_rf_fit2 <- last_fit(
  final_rf_wf2,
  split = data_split2,
  metrics = metric_set( # 直接在此擴充指標
    roc_auc, 
    accuracy,
    recall,     # 新增
    precision,  # 新增
    f_meas      # 新增
))

# Collect metrics
collect_metrics(final_rf_fit2)

```



```{r}
# 先載好必要的套件
library(vip)

# 畫 Variable Importance Plot
final_rf_fit2 %>%
  extract_fit_parsnip() %>%
  vip(num_features = 20)  # 只列出前20重要的變數

```

```{r}
# RF 混淆矩陣
rf_conf_mat <- final_rf_fit2 %>%
  collect_predictions() %>%
  conf_mat(truth = attrition_flag, estimate = .pred_class)

rf_conf_mat

```


```{r}
tidy(rf_recipe2, number = 4) |> 
  filter(terms != "(Intercept)")

```


```{r}
# 選數值變數
numeric_vars <- train_data2 %>% 
  select(where(is.numeric))
# 算相關矩陣
cor_matrix <- cor(numeric_vars, use = "complete.obs")

cor_matrix
# 找出相關大於0.7的變數組合
cor_matrix[abs(cor_matrix) > 0.7 & abs(cor_matrix) < 1]

```







# XGBoost - clean version


```{r}
# 3.1 Define XGBoost model
xgb_spec2 <- boost_tree(
  trees = tune(),
  tree_depth = tune(),
  learn_rate = tune(),
  loss_reduction = tune(),
  sample_size = tune(),
  mtry = tune()
) %>%
  set_engine("xgboost") %>%
  set_mode("classification")

# 3.2 Define Recipe（XGB也可以不用normalize）
xgb_recipe2 <- recipe(attrition_flag ~ ., data = train_data2) %>%
  step_other(all_nominal_predictors(), threshold = 0.05) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_zv(all_predictors()) %>%
  step_corr(threshold = 0.7)

# 3.3 Create Workflow
xgb_wf2 <- workflow() %>%
  add_model(xgb_spec2) %>%
  add_recipe(xgb_recipe2)

# 3.4 Define Grid
xgb_grid2 <- grid_latin_hypercube(
  trees(range = c(100, 1000)),
  tree_depth(range = c(2, 10)),
  learn_rate(range = c(0.01, 0.3)),
  loss_reduction(range = c(0.0001, 1)),
  sample_size = sample_prop(range = c(0.5, 1)),
  mtry(range = c(2, 10)),
  size = 20
)

# 3.5 Tune
xgb_tuned2 <- tune_grid(
  xgb_wf2,
  resamples = cross_validation_folds2,  # 用乾淨版 folds2
  grid = xgb_grid2,
  metrics = metric_set(roc_auc, accuracy)
)

# 3.6 Select best
xgb_best2 <- select_best(xgb_tuned2, metric = "roc_auc")

# 3.7 Finalize
final_xgb_wf2 <- finalize_workflow(xgb_wf2, xgb_best2)

# Last fit
final_xgb_fit2 <- last_fit(
  final_xgb_wf2,
  split = data_split2,
  metrics = metric_set( # 直接在此擴充指標
    roc_auc, 
    accuracy,
    recall,     # 新增
    precision,  # 新增
    f_meas      # 新增
))

# Collect metrics
collect_metrics(final_xgb_fit2)

```



```{r}
# XGB 混淆矩陣
xgb_conf_mat <- final_xgb_fit2 %>%
  collect_predictions() %>%
  conf_mat(truth = attrition_flag, estimate = .pred_class)

xgb_conf_mat

```




```{r}
# 快速比較所有模型 (範例程式碼)
library(purrr)
list(
  logistic = final_base_fit2,
  ridge = final_ridge_fit2,
  lasso = final_lasso_fit2,
  elastic = final_elastic_fit2,
  knn = knn_final_fit2,
  rf = final_rf_fit2,
  xgb = final_xgb_fit2
) %>% 
  map_dfr(~collect_metrics(.x) %>% 
            select(.metric, .estimate) %>% 
            pivot_wider(names_from = .metric, values_from = .estimate),
          .id = "model") %>% 
  arrange(desc(roc_auc))
```


# Random Forest (SMOTE版)

```{r}
#install.packages("themis")

library(themis)  # 用 SMOTE 要有這個 package

# 新版recipe
smote_recipe2 <- recipe(attrition_flag ~ ., data = train_data2) %>% 
  step_other(all_nominal_predictors(), threshold = 0.05) %>%
  step_zv(all_predictors()) %>%
  step_corr(all_numeric_predictors(), threshold = 0.7) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_normalize(all_numeric_predictors()) %>%
  step_smote(attrition_flag)   # 🔥 加上 SMOTE

```


```{r}

# Random Forest模型設定 (不用變)
rf_spec2 <- rand_forest(
  mtry = tune(),
  min_n = tune()
) %>%
  set_engine("ranger", importance = "impurity") %>%
  set_mode("classification")

# Workflow (用 smote_recipe2)
rf_smote_wf2 <- workflow() %>%
  add_model(rf_spec2) %>%
  add_recipe(smote_recipe2)

# Grid
rf_grid2 <- grid_regular(
  mtry(range = c(2, 10)),
  min_n(range = c(5, 30)),
  levels = 5
)

# Tune
rf_smote_tuned2 <- tune_grid(
  rf_smote_wf2,
  resamples = cross_validation_folds2,
  grid = rf_grid2,
  metrics = metric_set(roc_auc, accuracy)
)

# Select best
rf_smote_best2 <- select_best(rf_smote_tuned2, metric = "roc_auc")

# Finalize
rf_smote_final_wf2 <- finalize_workflow(rf_smote_wf2, rf_smote_best2)

# Last Fit
rf_smote_final_fit2 <- last_fit(
  rf_smote_final_wf2,
  split = data_split2,
  metrics = metric_set(roc_auc, accuracy, recall, precision, f_meas)
)

# Collect metrics
collect_metrics(rf_smote_final_fit2)
```




```{r}
# XGBoost模型設定 (不用變)
xgb_spec2 <- boost_tree(
  trees = tune(),
  tree_depth = tune(),
  learn_rate = tune(),
  loss_reduction = tune(),
  sample_size = tune(),
  mtry = tune()
) %>%
  set_engine("xgboost") %>%
  set_mode("classification")

# Workflow (用 smote_recipe2)
xgb_smote_wf2 <- workflow() %>%
  add_model(xgb_spec2) %>%
  add_recipe(smote_recipe2)

# Grid
xgb_grid2 <- grid_latin_hypercube(
  trees(range = c(100, 1000)),
  tree_depth(range = c(2, 10)),
  learn_rate(range = c(0.01, 0.3)),
  loss_reduction(range = c(0.0001, 1)),
  sample_size = sample_prop(range = c(0.5, 1)),
  mtry(range = c(2, 10)),
  size = 20
)

# Tune
xgb_smote_tuned2 <- tune_grid(
  xgb_smote_wf2,
  resamples = cross_validation_folds2,
  grid = xgb_grid2,
  metrics = metric_set(roc_auc, accuracy)
)

# Select best
xgb_smote_best2 <- select_best(xgb_smote_tuned2, metric = "roc_auc")

# Finalize
xgb_smote_final_wf2 <- finalize_workflow(xgb_smote_wf2, xgb_smote_best2)

# Last Fit
xgb_smote_final_fit2 <- last_fit(
  xgb_smote_final_wf2,
  split = data_split2,
  metrics = metric_set(roc_auc, accuracy, recall, precision, f_meas)
)

# Collect metrics
collect_metrics(xgb_smote_final_fit2)

```















# pca

```{r}
dim(train_data2)
```

```{r}
library(dplyr)

pca_varnames <- c(
  "customer_age",
  "total_trans_ct",
  "total_amt_chng_q4_q1",
  "avg_utilization_ratio",
  "credit_limit",
  "total_revolving_bal",
  "contacts_count_12_mon",
  "months_inactive_12_mon",
  "total_relationship_count"
)

train_numeric <- train_data2 %>%
  select(all_of(pca_varnames)) %>%
  na.omit()

# 再做 PCA
train_pca <- prcomp(train_numeric, center = TRUE, scale. = TRUE)

summary(train_pca)

```


```{r}
# 從 test_data2 選相同數值欄位（變數名稱要跟 train 相同）
test_numeric <- test_data2 %>%  
  select(all_of(pca_varnames)) %>%
  na.omit()
# 用 train 的 PCA rotation 對 test data 做投影（預測主成分）
test_pca_scores <- predict(train_pca, newdata = test_numeric)


```




```{r}
# Round the values in the rotation matrix of the PCA result to two decimal places
rounded_rotation <- round(train_pca$rotation, 2)

# Display the rotation matrix with rounded values
rounded_rotation
```
```{r}
# Display the values of the first row in the 'data' dataset
train_data2[1,]

# Display the loadings of the first principal component from the PCA rotation matrix
train_pca$rotation[, 1]

# Display the first few rows of the PCA scores matrix
head(train_pca$x) |> round(2)
```
```{r}
# 計算主成分的貢獻比例
variance_proportion <- train_pca$sdev^2 / sum(train_pca$sdev^2)

# 折線圖（簡單 base R）
plot(variance_proportion, type = "b", main = "Proportion of Variance by PCs")

# Scree plot (fviz_eig)
library(factoextra)

fviz_eig(train_pca, addlabels = TRUE, ylim = c(0, 50),
         barfill = "darkred", barcolor = "red")

# 加入 Kaiser rule 判線
fviz_eig(train_pca, addlabels = TRUE, choice="eigenvalue", main = "Figure 2") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "blue")

```


```{r}
expl_var <- round(variance_proportion[1:2] * 100, 1)
colnames(train_pca$x)[1:2] <- paste0("PC", 1:2, " (", expl_var, "%)")

```


主要目的：視覺化高維數據的結構
將多個與顧客行為相關的變數（例如：交易次數、信用額度、使用比例）降維到2維或3維，方便觀察顧客分佈與群體特徵。


```{r}
# 選擇數值變數並標準化（train set）
pca_train_vars <- train_data2 %>%
  select(all_of(pca_varnames)) %>%
  na.omit()

# 記得保留對應的 label
train_labels <- train_data2 %>%
  filter(complete.cases(select(., all_of(pca_varnames)))) %>%
  pull(attrition_flag)

# 執行 PCA
pca_result <- prcomp(pca_train_vars, center = TRUE, scale. = TRUE)

# 組合 PCA scores + labels
pca_data <- as.data.frame(pca_result$x[, 1:2])
pca_data$Attrition_Flag <- train_labels



library(ggplot2)

ggplot(pca_data, aes(x = PC1, y = PC2, color = Attrition_Flag)) +
  geom_point(alpha = 0.7, size = 2.5) +
  labs(title = "PCA of Customer Behavior (Training Set)",
       x = "Principal Component 1",
       y = "Principal Component 2",
       color = "Customer Status") +
  theme_minimal(base_size = 14)

```



```{r}
library(factoextra)

fviz_pca_biplot(pca_result,
                label = "var",
                habillage = train_labels,
                addEllipses = TRUE,
                col.var = "black",
                repel = TRUE,
                title = "PCA Biplot with Attrition (Train Only)")

```




# pca+logistic base model

```{r}

logistic_pca_recipe <- recipe(attrition_flag ~ ., data = train_data2) %>%
  step_select(all_of(c("attrition_flag", pca_varnames))) %>%     # ✅ 保留 Y 和指定變數
  step_normalize(all_of(pca_varnames)) %>%
  step_pca(all_of(pca_varnames), num_comp = 2)


# 使用相同的 model
logistic_spec_pca <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")

# 建立新的 workflow
logistic_pca_wf <- workflow() %>%
  add_model(logistic_spec_pca) %>%
  add_recipe(logistic_pca_recipe)


logistic_pca_cv <- fit_resamples(
  logistic_pca_wf,
  resamples = cross_validation_folds2,
  metrics = metric_set(roc_auc, accuracy)
)

collect_metrics(logistic_pca_cv)


final_logistic_pca_fit <- last_fit(
  logistic_pca_wf,
  split = data_split2,
  metrics = metric_set(
    roc_auc,
    accuracy,
    recall,
    precision,
    f_meas
  )
)

collect_metrics(final_logistic_pca_fit)

```

# logistic baseline for pca compare

```{r}
# 
logistic_9vars_spec <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")

# 
pca_varnames <- c(
  "customer_age",
  "total_trans_ct",
  "total_amt_chng_q4_q1",
  "avg_utilization_ratio",
  "credit_limit",
  "total_revolving_bal",
  "contacts_count_12_mon",
  "months_inactive_12_mon",
  "total_relationship_count"
)

# 
logistic_9vars_recipe <- recipe(attrition_flag ~ ., data = train_data2) %>%
  step_select(all_of(c("attrition_flag", pca_varnames))) %>%  # 保留欄位
  step_zv(all_predictors()) %>%                                # 剔除 zero variance
  step_corr(all_predictors(), threshold = 0.7) %>%             # 剃除共線性
  step_normalize(all_predictors())                             # 數值標準化

# workflow
logistic_9vars_wf <- workflow() %>%
  add_model(logistic_9vars_spec) %>%
  add_recipe(logistic_9vars_recipe)

# cross-validation
logistic_9vars_cv <- fit_resamples(
  logistic_9vars_wf,
  resamples = cross_validation_folds2,
  metrics = metric_set(roc_auc, accuracy)
)

# 
collect_metrics(logistic_9vars_cv)

# last fit
final_logistic_9vars_fit <- last_fit(
  logistic_9vars_wf,
  split = data_split2,
  metrics = metric_set(roc_auc, accuracy, recall, precision, f_meas)
)

# 看測試集效能
collect_metrics(final_logistic_9vars_fit)

```



# Generative Model

# LDA

```{r}
#install.packages("discrim")

library(discrim)  

lda_spec <- discrim_linear() %>%
  set_engine("MASS") %>%
  set_mode("classification")
#
pca_varnames <- c(
  "customer_age",
  "total_trans_ct",
  "total_amt_chng_q4_q1",
  "avg_utilization_ratio",
  "credit_limit",
  "total_revolving_bal",
  "contacts_count_12_mon",
  "months_inactive_12_mon",
  "total_relationship_count"
)

#  
lda_recipe <- recipe(attrition_flag ~ ., data = train_data2) %>%
  step_select(all_of(c("attrition_flag", pca_varnames))) %>%
  step_normalize(all_numeric_predictors())

lda_wflow <- workflow() %>%
  add_recipe(lda_recipe) %>%
  add_model(lda_spec)

# Cross-validation
lda_cv <- fit_resamples(
  lda_wflow,
  resamples = cross_validation_folds2,
  metrics = metric_set(roc_auc, accuracy)
)

# Last fit for test set performance
final_lda_fit <- last_fit(
  lda_wflow,
  split = data_split2,
  metrics = metric_set(roc_auc, accuracy, recall, precision, f_meas)
)

collect_metrics(final_lda_fit)

```


| model              | AUC   | Accuracy | Recall | Precision | F1 Score |
|--------------------|-------|----------|--------|-----------|----------|
| **PCA + Logistic** | 0.7699 | 0.8539   | 0.1748 | 0.6786    | 0.2780   |
| **Logistic      ** | 0.8901 | 0.8889   | 0.4847 | 0.7349    | 0.5841   |
| **LDA**            | 0.8876 | 0.8904   | 0.5061 | 0.7301    | 0.5978   |


LDA 在這裡的意義
可當作一種監督式降維的比較工具，幫你觀察哪些方向有分類效果。

不建議當作唯一預測基礎，你可以用 LDA 視覺化、或當成 baseline，但更高表現的模型還是 XGBoost 或 logistic + variable selection




```{r}
#載入 discrim 套件（若尚未安裝，先安裝）
# install.packages("discrim")
library(discrim)

# QDA 模型規格
qda_spec <- discrim_quad() %>%
  set_engine("MASS") %>%
  set_mode("classification")

# 用與 LDA 相同的變數與資料處理
pca_varnames <- c(
  "customer_age",
  "total_trans_ct",
  "total_amt_chng_q4_q1",
  "avg_utilization_ratio",
  "credit_limit",
  "total_revolving_bal",
  "contacts_count_12_mon",
  "months_inactive_12_mon",
  "total_relationship_count"
)

qda_recipe <- recipe(attrition_flag ~ ., data = train_data2) %>%
  step_select(all_of(c("attrition_flag", pca_varnames))) %>%
  step_normalize(all_numeric_predictors())

# workflow
qda_wflow <- workflow() %>%
  add_recipe(qda_recipe) %>%
  add_model(qda_spec)

# 
qda_cv <- fit_resamples(
  qda_wflow,
  resamples = cross_validation_folds2,
  metrics = metric_set(roc_auc, accuracy)
)

# 
final_qda_fit <- last_fit(
  qda_wflow,
  split = data_split2,
  metrics = metric_set(roc_auc, accuracy, recall, precision, f_meas)
)

# 
collect_metrics(final_qda_fit)

```

ROC AUC 高達 0.924，表示模型能有效區分兩類。

Recall 為 0.586，比 LDA 還好，表示它對流失客戶的抓取力更強。

整體在 accuracy、precision、F1 都優於 baseline logistic 和 PCA logistic。
